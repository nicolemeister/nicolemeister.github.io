<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Nicole Meister</title>
  
  <meta name="author" content="Nicole Meister">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Nicole Meister </name>
              </p>
              <p>Hello! ðŸ‘‹ I'm Nicole (she/her/hers), a first-year PhD student and NSF graduate fellow at Stanford University starting Fall 2022. 
                <br>
                <br>
                My research interests are broadly in computer vision and machine learning, particularly in building fair, robust, and interpretable AI systems.
              </p>
              <p>
                I graduated from Princeton University with a BSE in electrical and computer engineering and minors in cognitive science and robotics. I was fortunate to work in the
                <a href='https://visualai.princeton.edu/'>Princeton VisualAI Lab</a> and be advised by <a href='https://www.cs.princeton.edu/~olgarus/'>Prof. Olga Russakovsky</a>. 

                <br><br>
              </p>
              <p style="text-align:center">
                <a href="mailto:nmeist@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="data/NicoleMeister-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=2twOzaMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/nicolemeister/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/nicole-meister-063b29177/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/nicole__meister">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/NicoleMeister.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/NicoleMeister.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>News</heading>
              <p>
                <ul>
<li><b>July 2023:</b> Paper accepted to ICCV: <a href="https://princetonvisualai.github.io/gender-artifacts/"> Gender Artifacts in Visual Datasets</a> </li>
<li><b>July 2022:</b> Paper accepted to ECCV: <a href="https://princetonvisualai.github.io/HIVE/">HIVE: Evaluating the Human Interpretability of Visual Explanations</a> </li>
<li><b>June 2022:</b> Presented at CVPR workshops:<a href="https://princetonvisualai.github.io/gender-artifacts/"> Gender Artifacts in Visual Datasets</a> and <a href="https://princetonvisualai.github.io/HIVE/">HIVE</a> </li>
<li><b>May 2022:</b> Graduated from Princeton ðŸŽ“: received <a href="https://engineering.princeton.edu/news/2022/05/25/class-day-graduates-were-told-their-dedication-would-be-foundation-future-success">Calvin Dodd MacCracken Senior Thesis Award </a> (one of 3 students across all of Princeton Engineering), <a href="https://ece.princeton.edu/news/first-person-class-day-ceremony-3-years-honors-resilient-class-2022#:~:text=Class%20of%202022-,First%20in%2Dperson%20Class%20Day%20ceremony%20in%203,honors%20resilient%20Class%20of%202022&text=Princeton%20ECE%20honored%20its%2039,awards%20for%20outstanding%20academic%20achievement.">Sigma Xi Book Award for Outstanding Undergraduate Research</a> (one of 4 in 40 in department) </li>
<li><b>April 2022:</b> Awarded <a href="https://www.nsfgrfp.org/">NSFGRFP</a> </li>
<li><b>Sept 2021:</b> Interned at Adobe Research, developed new reading Adobe Acrobat tool for acronym definitions and built <a href="https://research.adobe.com/news/adobe-research-receives-paper-award-for-helping-readers-understand-acronyms/">acronym disambiguation dataset</a>) </li>
<li><b>March 2021:</b> Awarded <a href="https://blog.adobe.com/en/publish/2021/03/08/adobe-research-women-in-tech-scholarship-winners.html">Adobe Research Women-in-Technology Scholarship </a>($10k) </li>
<li><b>March 2021:</b> Published in the ReScienceC journal <a href="https://rescience.github.io/bibliography/Kim_2021.html">[Re] Don't Judge an Object by Its Context: Learning to Overcome Contextual Bias </a> (one of 23/82 reproducibility reports accepted) </li>
                </ul>  
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                <!-- I am interested in machine learning and computer vision, with an emphasis in algorithmic fairness and interpretability of AI systems.       -->
                <!-- I enjoy applying data and machine learning to social good applications to make sense of the world around me and expose gender/racial disparities. -->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" bgcolor="#ffffd0" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nothing" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/genderartifacts.jpeg' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://princetonvisualai.github.io/gender-artifacts/">
                <papertitle>Gender Artifacts in Visual Datasets </papertitle> 
              </a>
              <br>
            
                <a href=""></a>
                <strong>Nicole Meister*,</strong>
                <a href="https://dorazhao99.github.io/">Dora Zhao*, </a>
                <a href="https://angelina-wang.github.io/">Angelina Wang, </a> 
                <a href="https://www.cs.princeton.edu/~vr23/">Vikram V. Ramaswamy, </a>
                <a href="https://ruthcfong.github.io/">Dr. Ruth Fong, </a>
                <a href="https://www.cs.princeton.edu/~olgarus/">Prof. Olga Russakovsky</a>
              <br>
              <em>arxiv</em>, 2022
              <br>
              <a href="https://princetonvisualai.github.io/gender-artifacts/">[project page]</a>
              <a href="https://arxiv.org/abs/2206.09191">[paper]</a>
              <a href="https://github.com/princetonvisualai/gender-artifacts">[code]</a>

              <p></p>
              <p>
                We explore to what extent gendered information can truly be removed from the dataset. We develop a framework to identify gender artifacts, or visual cues that are correlated with gender.
              </p>
            </td>
          </tr> 

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/HIVE.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/HIVE.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://princetonvisualai.github.io/HIVE/">
                <papertitle>HIVE: Evaluating the Human Interpretability of Visual Explanations</papertitle> 
              </a>
              <br>
            
                <a href=""></a>
                <a href="https://sunniesuhyoung.github.io/">Sunnie S. Y. Kim, </a>
                <strong>Nicole Meister</strong>, 
                <a href="https://www.cs.princeton.edu/~vr23/">Vikram V. Ramaswamy, </a>
                <a href="https://ruthcfong.github.io/">Dr. Ruth Fong, </a>
                <a href="https://www.cs.princeton.edu/~olgarus/">Prof. Olga Russakovsky</a>
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://princetonvisualai.github.io/HIVE/">[project page]</a>
              <a href="https://arxiv.org/abs/2112.03184">[paper]</a>
              <a href="https://github.com/princetonvisualai/HIVE">[code]</a>

              <p></p>
              <p>
                Human evaluation framework for diverse interpretability methods in computer vision.
                We identify two desiderata for explanations used to assist human decision making: <br>
                (1) Explanations should allow users to distinguish between correct and incorrect predictions. <br>
                (2) Explanations should be understandable to users.
              </p>
            </td>
          </tr> 


          <tr onmouseout="rawnerf_stop()" onmouseover="rawnerf_start()"  bgcolor="#ffffd0" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='rawnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/rawnerf.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mlrc.png' width="160">
              </div>
              <script type="text/javascript">
                function rawnerf_start() {
                  document.getElementById('rawnerf_image').style.opacity = "1";
                }

                function rawnerf_stop() {
                  document.getElementById('rawnerf_image').style.opacity = "0";
                }
                rawnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://rescience.github.io/bibliography/Kim_2021.html">
                <papertitle>[Re] Don't Judge an Object by Its Context: Learning to Overcome Contextual Bias</papertitle>
              </a>
              <br>
              <a href="https://sunniesuhyoung.github.io/">Sunnie S. Y. Kim</a>,
              <a href="https://sxzhang25.github.io/">Sharon Zhang</a>,
              <strong>Nicole Meister</strong>,
              <a href="https://www.cs.princeton.edu/~olgarus/">Olga Russakovsky</a>
              <br>
              <em>ReScience C</em>, 2021
              <br>
              <a href="https://rescience.github.io/bibliography/Kim_2021.html"> [journal]  </a>
              <a href="https://arxiv.org/abs/2104.13582"> [arXiv]  </a>
              <a href="https://openreview.net/forum?id=PRXM8-O9PKd"> [openreview]  </a>
              <a href="https://github.com/princetonvisualai/ContextualBias"> [code] </a>
              <p></p>
              <p>
                Participated in <a href='https://paperswithcode.com/rc2020'>ML Reproducibility Challenge 2020</a> and reproduced from scratch <a href='https://openaccess.thecvf.com/content_CVPR_2020/html/Singh_Dont_Judge_an_Object_by_Its_Context_Learning_to_Overcome_CVPR_2020_paper.html'>Singh et al. (CVPR 2020)</a> 
                that mitigates contextual bias in object and attribute recognition. <br>
                One of 23/82 reports accepted for publication to <em>ReScience C</em>, a peer-reviewed journal for new implementations and explicit replications of previously published papers.
            </td>
          </tr> 




          <tr onmouseout="rawnerf_stop()" onmouseover="rawnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='rawnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/rawnerf.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/jhuapl.jpg' width="160">
              </div>
              <script type="text/javascript">
                function rawnerf_start() {
                  document.getElementById('rawnerf_image').style.opacity = "1";
                }

                function rawnerf_stop() {
                  document.getElementById('rawnerf_image').style.opacity = "0";
                }
                rawnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href='https://actrims.confex.com/actrims/2019/meetingapp.cgi/Paper/4010'>
                <papertitle>Methods to Identify Patient Clusters and Build Precision Analytics for Diagnosis</papertitle>
              </a>
              <br>
              <strong>Nicole Meister</strong>, Hannah Cowley, Corban Rivera, Karla M Gray-Roncal, Kathryn Fitzgerald, Claudia Allshouse, Anna Duerr, Aalok Shah, Paul Nagy, Peter A Calabresi, Antony Rosen, Ellen M Mowry, 
              <a href='https://ep.jhu.edu/faculty/william-gray-roncal/'>William R Gray-Roncal</a>             
              <br>
              <em> Americas Committee for Treatment and Research in Multiple Sclerosis (ACTRIMS) </em>, 2019
              <br>
              <a href="https://drive.google.com/file/d/1hKGk15NwWmRDiFFQoeKcuEBVni3KwzXd/view?usp=sharing"> [poster] </a>
              <a href="https://actrims.confex.com/actrims/2019/meetingapp.cgi/Paper/4010"> [abstract] </a>
              <p></p>
              <p>
                Implemented machine learning algorithms to predict prognosis of Multiple Sclerosis patients (able to predict walk time within 1 second accuracy). 
                Used k-means to cluster patients and produce more accurate predictions.
              </td>
          </tr> 

          
        </tbody></table>

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Research Experiences</heading>
              <p>                
                I have had the privilege of working with some amazing labs and groups.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/AdobeGif.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/adobe.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://research.adobe.com/research/natural-language-processing/">
                <papertitle>Adobe NLP Research Intern (Summer 2021)</papertitle>
              </a>
              <br>
              <strong>Nicole Meister</strong>, Walter Chang, Tushar Dublish, Franck Dernoncourt
              <br>
              <a href="https://drive.google.com/file/d/1QCi-M20RlI-ewXU0YUznU0RoZbT8HJLN/view?usp=sharing">[presentation]</a>
              <a href="https://drive.google.com/file/d/1qWkCDrosVlFYkOIpyuTmcm1ut7luETB9/view?usp=sharing">[video]</a>
              <a href="https://drive.google.com/file/d/1MDRcjmpLmQX5ISb_JRaowtegHPLVUOcC/view?usp=sharing">[20 second demo]</a>
              <a href="https://research.adobe.com/news/adobe-research-receives-paper-award-for-helping-readers-understand-acronyms/">[media]</a>
              <a href="https://blog.adobe.com/en/publish/2021/03/08/adobe-research-women-in-tech-scholarship-winners">[award]</a>
              <p></p>
              <p>
                New reading assistant tool in Acrobat (SmartAcronyms) that extracts acronyms and their definition from text with 95% accuracy, improved speed (21x) of existing acronym extraction method while maintaining precision and recall. <br>
                Selected to present internship project to Adobe CEO and Adobe Research VP at 2021 Adobe Award Symposium. <br>
                <a href='https://blog.adobe.com/en/publish/2021/03/08/adobe-research-women-in-tech-scholarship-winners>'><b>Adobe Research Women-In-Tech Scholarship Winner</b></a>($10k)<br>

              </p>
            </td>
          </tr> 
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/junior_iw.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://e4e.ucsd.edu/">
                <papertitle>Junior Independent Work (Spring 2021)</papertitle>
              </a>
              <br>
              <strong>Nicole Meister</strong>, Sunnie Kim, Olga Russakovsky
            
              <br>
              <a href="https://github.com/nicolemeister/Junior_Indepdent_Work/blob/main/IW%20Presentation.pdf">[presentation]</a>
              <a href="https://github.com/nicolemeister/Junior_Indepdent_Work/blob/main/NMEISTER_JUNIOR_IW%20(7).pdf">[paper]</a>
              <a href="https://github.com/nicolemeister/Junior_Indepdent_Work">[code]</a>
              <p></p>
              <p>
              
                Decision rule method to selectively choose when to apply a model that performed well on 
                out-of-context images and one that performed well on in-context images. <br>
                Explored image prediction confidence estimates and saliency heatmaps (interpretability methods).
              </p>
            </td>
          </tr> 
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mangrove-vid.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/mangrove.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://e4e.ucsd.edu/">
                <papertitle>UCSD REU (Summer 2020)</papertitle>
              </a>
              <br>
              <strong>Nicole Meister</strong>, Dillon Hicks, Prof. Ryan Kastner
            
              <br>
              <a href="https://www.youtube.com/watch?v=obCpmMlv9pw&ab_channel=UCSanDiegoEngineersforExploration">[presentation]</a>
              <a href="https://www.youtube.com/watch?v=BhOYCPnyRhs">[demo]</a>
              <a href="https://github.com/nicolemeister/web-mangrove">[code]</a>
              <a href="https://cse.ucsd.edu/about/news/cse-research-sets-two-students-ncwit-collegiate-award">[award]</a>
              <p></p>
              <p>
                Web application to allow conservation groups to use CNNs to quantify and monitor mangroves.
                Finalist for <a href='https://cse.ucsd.edu/about/news/cse-research-sets-two-students-ncwit-collegiate-award/'>NCWIT Collegiate Award. </a> 
              </p>
            </td>
          </tr>
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/max-planck.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.exc.uni-konstanz.de/en/collective-behaviour/news-and-events/news/details/Introducing-the-summer-interns/">
                <papertitle>
                  Max Planck Institute for Collective Behavior (Summer 2019)
                  </papertitle>
              </a>
              <br>
              <strong>Nicole Meister</strong>,
               <a href="https://collectivebehaviour.com/people/graving-jake/">  Jake Graving, </a>
              <a href="https://collectivebehaviour.com/people/couzin-iain/">Prof. Ian Couzin</a>
              <br>
              <a href="https://github.com/nicolemeister/Junior_Indepdent_Work/blob/main/IW%20Presentation.pdf">[presentation]</a>
              <p></p>
              <p>
                Python based toolkit to identify and classify tactile interactions from a locust experiment video.
                Used toolkit to analyze locust limb interactions to better understand individual behavior.
              </p>
            </td>
          </tr> 
          
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects</heading>
              <p>
                I am grateful to my professors for their mentorship in projects exploring in algorithmic bias, interpretability, and more.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <!-- COS 529-->
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br>
                <img src='images/cos529.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Anyone Can Skateboard: Tracing Sources of Gender Biases in Classifiers</papertitle>
              <br>
              <strong>Nicole Meister*</strong>, Dora Zhao*, Prof. Jia Deng
              <br>
							<em>Advanced Computer Vision (Grad) Course Project</em>, Fall 2021
              <br>
              <a href="https://drive.google.com/file/d/1rb8AAir1GnYK5DZGT6_8V8dy6uR_qVde/view?usp=sharing">[paper]</a>
              <a href="https://github.com/dorazhao99/cos-529/">[code]</a>
              <p></p>
              <p>
                Exploring the role of contextual objects in gender bias of computer vision models.
                 <em>(Python, Pytorch)</em></p>
            </td>
          </tr> 

           <!--PSY 360-->
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br>
                <img src='images/psy360.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Does This Looks Like That? Comparing Human and ProtoPNet Prototypical Representations</papertitle>
              <br>
              <strong>Nicole Meister</strong>, Prof. Tom Griffiths
              <br>
							<em>Computational Models of Cognition Course Project</em>, Fall 2021
              <br>
              <a href="https://drive.google.com/file/d/1V-4xR26ubTaoFE9DCpYegZcJifrTt8B2/view?usp=sharing">[paper]</a>
              <a href="https://github.com/nicolemeister/PSY360">[code]</a>
              <p></p>
              <p> Conducted human study to evaluate and understand if the representations and prototypes 
                identified by a computer vision interpretability method capture a sense of typicality and align with a human's concept of prototypes. <em>(Python)</em></p>
            </td>
          </tr> 


          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br>
                <img src='images/DebiasingAlg.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Exploring Debiasing Sentence Representation</papertitle>
              <br>
              Grace Cuenca*, Leslie Kim*, <strong>Nicole Meister*</strong>, Prof. Karthik Narasimhan, Prof. Danqi Chen
              <br>
							<em>NLP Course Project</em>, Spring 2021
              <br>
              <a href="https://drive.google.com/file/d/1EiLfxeZJ5IKoYyinZIeurbjIWql7qNlJ/view?usp=sharing">[paper]</a>
              <a href="https://drive.google.com/file/d/1a9r4vyXkvw_03rF2ZDwD5ZKvccHahQvI/view?usp=sharing">[poster]</a>
              <a href="https://github.com/nicolemeister/COS484-SENTDEBIAS">[code]</a>
              <p></p>
              <p>Reproduced <a href='https://aclanthology.org/2020.acl-main.488/'>Liang et. al</a> method to debias sentence representations, 
                researched effects of size of context window on method <em>(Python)</em></p>
            </td>
          </tr> 



          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/carlabvid.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/carlab_pic.jpg' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Dance Dance Revolution (DDR) Robot </papertitle>
              <br>
              <strong>Nicole Meister*</strong>, Janet Wang*
              <br>
							<em>Robotics Course Project</em>, Spring 2021
              <br>
              <a href="https://docs.google.com/document/d/1bVi1kKObe4_R8Rdxq25F8g0HoCZJoTWztl1WIj5yQHQ/edit?usp=sharing">[report]</a>
              <a href="https://www.youtube.com/watch?v=YOPJRnu6I_o&t=9s&ab_channel=NicoleMeister">[video]</a>
              <p></p>
              <p>Omni-wheeled robot that plays DDR by using computer vision to process DDR videos to extract dance moves (up, down left, right) to move and
                flash LED strip colors accordingly <em>(Arduino, Python)</em></p>
            </td>
          </tr> 

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/asl.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Exploring Impact of Facial Feature Segmentation on American Sign Language Recognition</papertitle>
              <br>
              Helen Chen*, Grace Cuenca*, <strong>Nicole Meister*</strong>, Prof. Olga Russakovsky
              <br>
							<em>Computer Vision Course Project</em>, Fall 2020
              <br>
              <a href="https://drive.google.com/file/d/1QQ9z9kr_HNCHvPJGUqHd-TaEcU4vJId6/view?usp=sharing">[paper]</a>
              <a href="https://github.com/nicolemeister/COS429_ASL_Recognition">[code]</a>
              <p></p>
              <p>CNN-LSTM to recognize ASL gestures with 95% accuracy <em>(Pytorch, Python)</em></p>
            </td>
          </tr> 
          
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/pac-video.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/pac-schedule.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Princeton Dance Schedule</papertitle>
              <br>
              Helen Chen*, Angela Li*, <strong>Nicole Meister*</strong>, Edward Tian*, Prof. Robert Dondero
              <br>
							<em>Advanced Programming Techniques Course Project</em>, Spring 2020
              <br>
              
              <a href="https://pac-schedule.herokuapp.com/homepage">[website]</a>
              <a href="https://docs.google.com/presentation/d/1XAfBu4Nds04n3szQJWfSaGBOiuSKOEtWpAYI8C35zZo/edit?usp=sharing">[presentation]</a>
              <a href="https://docs.google.com/document/d/1MTa-LzHYzvYhVeHyqqwuU0eIU21V5zrvj4tz42f6Lvk/edit?usp=sharing">[project overview]</a>
              <a href="https://docs.google.com/document/d/1Ued2ogyClAcqxsEnKldeEOFDcf_uJPp0-Rk0D3Lxd4M/edit?usp=sharing">[programmer's guide]</a>
              <a href="https://docs.google.com/document/d/1j3wFm05UD-J7zkf6lQEByRVAtuHTG6xP1vYAs2PhkxE/edit?usp=sharing">[user's guide]</a>
              <a href="https://github.com/Helen300/PAC-Scheduling">[code]</a>
              <p></p>
              <p>Website to schedule and book dance studios. I worked on front-end and back-end to implement a scheduling algorithm to replace
                40 hours of administrative work (currently used by Princeton Arts Council to schedule spaces) Advisor: Prof. Dondero <em>(Python, Django, SQL, HTML/CSS, JavaScript,
                  JQuery, Bootstrap, Heroku)</em></p>
            </td>
          </tr> 
          
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching & Outreach</heading>
              <p>
                Creating inclusive spaces is extremely important to me as
                supportive environments have been crucial to my decision to pursue a graduate degree.

                I am extremely privileged to study at Princeton and want to 
                (1) help Princeton students succeed 
                (2) liberate the resources of an elite institution to support and uplift others.

              </p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br>
                <img src='images/princeton.png' style='vertical-align:middle;horizontal-align:middle' width="100">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Princeton TA & Grader</papertitle>
              <br>
              TA: Hold office hours, debug and grade assignments and exams. <br>
              Grader: Provide feedback to students regarding style, efficiency, design <br>
              <strong>ECE/COS 306 TA:</strong> Contemporary Logic Design (Fall 2021) <br>
              <strong>COS 429 TA & Grader: </strong> Computer Vision (Fall 2021) <br>
              <strong>COS 217 Grader: </strong>Introduction to Programming Systems (Spring 2020) <br>
              <strong>Peer Tutor </strong>for Introductory Computer Science Classes (Fall 2019-Spring 2021)  <br>


            </td>
          </tr> 


          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/ruha-dssg.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/dssg.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dataforsocialgood.weebly.com/">
                <papertitle>Data Science for Social Good</papertitle>
             
              </a>
              <br>
              <em>Founder</em> (Summer 2020, 2021)
              <br>
              <a href="https://dataforsocialgood.weebly.com/2020.html">[2020 recap]</a>
              <a href="https://docs.google.com/document/d/105xJIrAc56_RCYiCIL2jt_a7QYqAsCupvStjeOGgRqQ/edit?usp=sharing">[report]</a>
              <a href="https://github.com/nicolemeister/teaching-python-samples">[example lessons]</a>
              
              <p></p>
              <p>Created a free 6-week course to empower high school students from historically underrepresented minority groups with the skills to leverage data science and web development. 
                <br>
                Taught 20 hours/week online, prepared detailed lesson plans, mentored 21 students to
                complete data science project. 
                <br>
                Improved program in second year by recruiting 10 program alumni to teach, advertise, and coordinate logistics of program.
              </p>
            </td>
          </tr> 

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/scioly-vid.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/scioly.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://scioly.princeton.edu/past/2020/index">
                <papertitle>Princeton Science Olympiad</papertitle>
              </a>
              <br>
							<em>Co-Director</em>, 2020
              <br>
              <a href="https://drive.google.com/file/d/1O7Rgcz5I1VJUgpA3Wb1V4oLA37J_KzwH/view?usp=sharing">[report]</a>
              <a href="https://www.facebook.com/princetonscioly/videos/1366006530273252">[video]</a>
              <a href="https://www.facebook.com/media/set/?set=a.884773695282646&type=3">[photos]</a>
              
              <p></p>
              <p>Organized high school science competition, managing 30 person team, $23k budget, 140 volunteers, 800 participants. 
                <br>
                Prioritized accessibility, becoming first ever invitational to provide travel scholarships to teams and no attendance fee.</p>
            </td>
          </tr> 

          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <br><br>
                <img src='images/oa.png' style='vertical-align:middle' width="160">

              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://outdooraction.princeton.edu/">
                <papertitle>Princeton Outdoor Action (Freshman Orientation)</papertitle>
              </a>
              <p></p>
              <strong>Leader Trainer, Technical Skills Trainer, DEI Committee</strong>
              <br>
              Plan and lead a weeklong immersion program through backcountry backpacking. <br>
              Teach other leaders-in-training necessary backcountry backpacking techniques and other leadership skills. <br>
            </td>
          </tr> 




        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Design and source code from <a href="https://jonbarron.info/">Jon Barron's website </a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
